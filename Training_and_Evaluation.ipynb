{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###Install required libraries for finetuning a model in HuggingFace"
      ],
      "metadata": {
        "id": "08aBRK5iMcor"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNnkgBq7Q3EU",
        "outputId": "b28ee3b7-65a7-4a6e-9c90-02f2ad70945e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q -U trl transformers accelerate git+https://github.com/huggingface/peft.git\n",
        "!pip install -q -U datasets bitsandbytes einops wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMX6KCJKtsLx",
        "outputId": "0c65aac5-46ee-4ae7-ee1f-dbec6f29573a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git\n",
            "  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-vcwysu96/unsloth_87ab6b4b95bb4c2db5b9fc439c2b4fb9\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-vcwysu96/unsloth_87ab6b4b95bb4c2db5b9fc439c2b4fb9\n",
            "  Resolved https://github.com/unslothai/unsloth.git to commit a7bfbe7927ea75f959e1d7c84e7bf50945d405ff\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (24.1)\n",
            "Requirement already satisfied: tyro in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.8.5)\n",
            "Requirement already satisfied: transformers>=4.43.2 in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.43.3)\n",
            "Requirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.20.0)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (5.9.5)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.43.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.25.2)\n",
            "Requirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.20.3)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.23.5)\n",
            "Requirement already satisfied: hf-transfer in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.15.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (17.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.9.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.12.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.43.2->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.43.2->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.43.2->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.19.1)\n",
            "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (13.7.1)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.7.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.7.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.16.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Load the base model \"Llama-3 8b\" in quantized form for efficient memory usage"
      ],
      "metadata": {
        "id": "lKRHBFWWPpr5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174,
          "referenced_widgets": [
            "aac286d0588947628dd7f7d649e85c40",
            "eba0280d5d364f6f8d1d5cd0997cb267",
            "4c82fa1abaa84ee1865e7ce134f423f0",
            "b01b8cb42da3476ebac672ec74fa6023",
            "4c4f22c9f086486bb725b25a5058a958",
            "6351c61e782945598cdb36ef95e316ee",
            "30f6ff0294294f3b860194b54a67d9f1",
            "d0ab6e1f7be54077b2e842ab10b87014",
            "36d75da0480442c1bc0282472dd3dd53",
            "78d5a6021faf4c4490f37d6b2363ed0d",
            "78248972f1c14accb3a0297ea30d1bb3",
            "c2ed31781ec2428bb69f28e3c3529649",
            "a9da3159492b4b4f90f47abac3c25ece",
            "d15a923b99614b4e87bcfef98b2d070a",
            "ed8590016d7c4c7081be2a9e18229976",
            "9a1ea13157a5497483706e6b83baca2a",
            "ec60c5fa018c46bfb4dedb12f888db17",
            "72c3fa0a195d433686fab0e8d4b00004",
            "ad51e64d5b864691b168f1fc31861f04",
            "03134366a494446fbef4bd7bae88b7db",
            "12340872cad5492799e89366d689dbd5",
            "c90692b688cd4fc38c83d797163583f3"
          ]
        },
        "id": "7UrQNHys2RD6",
        "outputId": "fdebb731-6a66-4733-bde4-eb7d740b7e76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/quantizers/auto.py:174: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
            "  warnings.warn(warning_msg)\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/5.70G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aac286d0588947628dd7f7d649e85c40"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/172 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c2ed31781ec2428bb69f28e3c3529649"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Load the model\n",
        "\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, AutoTokenizer\n",
        "\n",
        "model_name = \"unsloth/llama-3-8b-bnb-4bit\"\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    trust_remote_code=True\n",
        ")\n",
        "model.config.use_cache = False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the tokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "id": "OJKYp15L0AuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Load the three datasets from HuggingFace to fine-tune the LLAMA3 model"
      ],
      "metadata": {
        "id": "HM-XQRr7Mogs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, Dataset\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "yuemJoyoR8dq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset 1 - \"CodeExercise-Python-27k\" \\\\\n",
        "**NOTE:** We were not able to directly load this dataset from HuggingFace, thus we cloned it and manipulated the JSON file to extract the necessary information"
      ],
      "metadata": {
        "id": "A5ZV_eTYRWAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the dataset\n",
        "\n",
        "!git clone https://huggingface.co/datasets/codefuse-ai/CodeExercise-Python-27k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azpdyZEMaFb5",
        "outputId": "d54ef249-9744-430a-fa8c-2da31484fee5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'CodeExercise-Python-27k' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd CodeExercise-Python-27k\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIeZ4d94bmG-",
        "outputId": "8cd81b96-8915-4f38-a133-053d694053fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CodeExercise-Python-27k\n",
            "approach-en.png  CodeExercise-Python-27k.json  LOGO.png\t\t\t README.md\n",
            "approach.png\t LICENSE\t\t       preprocessed_dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the JSON lines contained in the dataset and store in a list \"data\"\n",
        "\n",
        "import json\n",
        "\n",
        "data = []\n",
        "\n",
        "with open('CodeExercise-Python-27k.json') as f:\n",
        "    for line in f:\n",
        "        try:\n",
        "            # Parse each line as a JSON object and append to the list\n",
        "            data.append(json.loads(line.strip()))\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"Error decoding JSON: {e}\")\n",
        "            continue"
      ],
      "metadata": {
        "id": "1Zz2JX98cfMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the different key-value pairs in the JSON lines to extract the proper information\n",
        "\n",
        "print(data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5B80nqFdVPY",
        "outputId": "38f0326f-a584-40c9-86c1-3f8e92053cd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'data_name': 'CodeExercise-Py', 'id': 0, 'chat_rounds': [{'role': 'human', 'content': 'Write a Python function named \"add_numbers\" that takes two parameters, \"num1\" and \"num2\", and returns the sum of the two numbers.\\nInput: None', 'chat_round_id': 0}, {'role': 'bot', 'content': '```python\\ndef add_numbers(num1, num2):\\n    \"\"\"\\n    This function takes two numbers as input and returns their sum.\\n\\n    Parameters:\\n    num1 (int or float): The first number.\\n    num2 (int or float): The second number.\\n\\n    Returns:\\n    int or float: The sum of num1 and num2.\\n    \"\"\"\\n    return num1 + num2\\n\\n# Example usage\\nresult = add_numbers(5, 3)\\nprint(result)  # Output: 8\\n\\n\\n```', 'chat_round_id': 1}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the features 'human' and 'bot' from the JSON files and store them in lists \"prompts\" and \"respnses\" respectively\n",
        "# then save the stored information into a csv file as a DataFrame\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize lists to hold the prompts and responses\n",
        "prompts = []\n",
        "responses = []\n",
        "\n",
        "# Iterate through the list of data\n",
        "for item in data:\n",
        "    # Extract the 'human' and 'bot' content\n",
        "    human_content = None\n",
        "    bot_content = None\n",
        "    for round in item['chat_rounds']:\n",
        "        if round['role'] == 'human':\n",
        "            human_content = round['content']\n",
        "        elif round['role'] == 'bot':\n",
        "            bot_content = round['content']\n",
        "\n",
        "    # Append to the lists\n",
        "    prompts.append(human_content)\n",
        "    responses.append(bot_content)\n",
        "\n",
        "# Create a DataFrame with two columns: 'prompt' and 'response'\n",
        "df = pd.DataFrame({\n",
        "    'prompt': prompts,\n",
        "    'response': responses\n",
        "})\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df.head())\n",
        "\n",
        "# Optionally, save the DataFrame to a CSV file\n",
        "df.to_csv('preprocessed_dataset.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GflmymYgwmz",
        "outputId": "563eee30-12d1-4f4e-e7db-c5d65b10e538"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              prompt  \\\n",
            "0  Write a Python function named \"add_numbers\" th...   \n",
            "1  Write a Python function named \"multiply_number...   \n",
            "2  Write a Python function named \"power_of\" that ...   \n",
            "3  Write a Python function named \"is_even\" that t...   \n",
            "4  Write a Python function named \"is_prime\" that ...   \n",
            "\n",
            "                                            response  \n",
            "0  ```python\\ndef add_numbers(num1, num2):\\n    \"...  \n",
            "1  ```python\\ndef multiply_numbers(num1, num2):\\n...  \n",
            "2  ```python\\ndef power_of(base, exponent):\\n    ...  \n",
            "3  ```python\\ndef is_even(number):\\n    \"\"\"\\n    ...  \n",
            "4  ```python\\ndef is_prime(number):\\n    \"\"\"\\n   ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0X3kHnskSWU4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fa075e9-ade8-4345-9d85-311a0d2b217c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Read the csv file\n",
        "dataset_1 = pd.read_csv('/content/CodeExercise-Python-27k/preprocessed_dataset.csv')\n",
        "\n",
        "# Convert the DataFrame to a Hugging Face Dataset\n",
        "dataset_1 = Dataset.from_pandas(dataset_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset2 - \"ibl-best-practices-instructor-dataset\""
      ],
      "metadata": {
        "id": "VQ4AIA33Rg2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset from HuggingFace\n",
        "\n",
        "dataset_2 = load_dataset(\"iblai/ibl-best-practices-instructor-dataset\", split=\"train\")"
      ],
      "metadata": {
        "id": "bKb6Ex7ZRywB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset 3 - \"PythonTutor-Evol-1k-DPO-GPT4_vs_35\""
      ],
      "metadata": {
        "id": "8A59aC0oRk_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset from HuggingFace\n",
        "\n",
        "dataset_3 = load_dataset(\"KrisPi/PythonTutor-Evol-1k-DPO-GPT4_vs_35\", split=\"train\")"
      ],
      "metadata": {
        "id": "t2WWj9n_R0IB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data Pre-processing"
      ],
      "metadata": {
        "id": "5g9PMTK7Sv3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the feature columns of the three datasets\n",
        "\n",
        "print(dataset_1.column_names)\n",
        "print(dataset_2.column_names)\n",
        "print(dataset_3.column_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxUEb0dEnn2R",
        "outputId": "9cdaa3ff-e959-4600-e04f-b8cd401df755"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['prompt', 'response']\n",
            "['virtue', 'prompt', 'response']\n",
            "['instruction', 'output', 'gpt4_output']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the feature names 'instruction' to 'prompt' and 'output' to 'response' in Dataset 3\n",
        "def preprocess_dataset(dataset, prompt_col, response_col):\n",
        "    return dataset.rename_column(prompt_col, \"prompt\").rename_column(response_col, \"response\")\n",
        "\n",
        "dataset_3 = preprocess_dataset(dataset_3, 'instruction', 'output')"
      ],
      "metadata": {
        "id": "9b5AGTNU4YfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset_1.column_names)\n",
        "print(dataset_2.column_names)\n",
        "print(dataset_3.column_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-0V5hZH4fF7",
        "outputId": "c9faaa85-f997-49fe-e724-b83ba2e0ccd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['prompt', 'response']\n",
            "['virtue', 'prompt', 'response']\n",
            "['prompt', 'response', 'gpt4_output']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate the three datasets into one combined dataset\n",
        "\n",
        "from datasets import concatenate_datasets\n",
        "combined_dataset = concatenate_datasets([dataset_1, dataset_2, dataset_3])"
      ],
      "metadata": {
        "id": "latIWOxr4---"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmIDiG1E5HE5",
        "outputId": "605a4bc1-76f5-4afb-9437-21cd0bdd05c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['prompt', 'response', 'virtue', 'gpt4_output'],\n",
              "    num_rows: 28547\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the combined dataset\n",
        "shuffled_dataset = combined_dataset.shuffle(seed=42)"
      ],
      "metadata": {
        "id": "PEwMRQThGeuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shuffled_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6A8RdsAWGe1w",
        "outputId": "e88e8e88-83bd-4f27-e5ea-c7a948b82e8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['prompt', 'response', 'virtue', 'gpt4_output'],\n",
              "    num_rows: 28547\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove columns that are not needed for training ('virtue' and 'gpt4_output')\n",
        "shuffled_dataset = shuffled_dataset.remove_columns([\"virtue\", \"gpt4_output\"])\n",
        "shuffled_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Vq-LVg2hJq9",
        "outputId": "7f29aaae-4173-4645-d8aa-f3b5bb1a1bdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['prompt', 'response'],\n",
              "    num_rows: 28547\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Format the shuffled dataset to one form that has its contect in the field \"text\"\n",
        "\n",
        "prompt = \"\"\"Below is an instruction that describes a question. Write a response that appropriately completes the request.\n",
        "\n",
        "### prompt:\n",
        "{}\n",
        "\n",
        "### response:\n",
        "{}\"\"\"\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
        "def formatting_prompts_func(examples):\n",
        "    prompt = examples[\"prompt\"]\n",
        "    response = examples[\"response\"]\n",
        "    texts = []\n",
        "    for prompt, response in zip(prompt, response):\n",
        "        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n",
        "        text = prompt.format(prompt, response) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "    return { \"text\" : texts, }\n",
        "pass\n",
        "\n",
        "\n",
        "shuffled_dataset = shuffled_dataset.map(formatting_prompts_func, batched = True,)"
      ],
      "metadata": {
        "id": "EORaJB1kulbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shuffled_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wp3mNBIfiMIw",
        "outputId": "ba1208fe-b37e-4abe-a964-dda75eeb17e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['prompt', 'response', 'text'],\n",
              "    num_rows: 28547\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the shuffled dataset to prepare for training\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"])\n",
        "\n",
        "tokenized_dataset = shuffled_dataset.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "id": "BOyOVwM0h2A-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63ZXMAhJiScD",
        "outputId": "c4826e4c-af27-4548-f468-95edaeefd3da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['prompt', 'response', 'text', 'input_ids', 'attention_mask'],\n",
              "    num_rows: 28547\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the tokenized data into 80% for training and 20% for testing\n",
        "train_test_split = tokenized_dataset.train_test_split(test_size=0.2, seed=42)\n",
        "train_dataset = train_test_split['train']\n",
        "test_dataset = train_test_split['test']"
      ],
      "metadata": {
        "id": "kChRKlWWqVzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Training and Evaluation"
      ],
      "metadata": {
        "id": "CI7EnUHWUlVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure the QLora adapters for efficient finetuning\n",
        "\n",
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "lora_alpha = 16\n",
        "lora_dropout = 0\n",
        "lora_r = 64\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "    lora_alpha=lora_alpha,\n",
        "    lora_dropout=lora_dropout,\n",
        "    r=lora_r,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                       \"gate_proj\", \"up_proj\", \"down_proj\",]\n",
        ")\n",
        "\n",
        "# enabling gradient checkpointing before the PEFT model\n",
        "model.enable_input_require_grads()\n",
        "\n",
        "model = get_peft_model(model, peft_config)"
      ],
      "metadata": {
        "id": "bEj6pWMAuc21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bArGWrpW7MJQ"
      },
      "outputs": [],
      "source": [
        "# Define the training arguments\n",
        "\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "output_dir = \"./results\"\n",
        "per_device_train_batch_size = 1\n",
        "gradient_accumulation_steps = 8\n",
        "optim = \"adamw_8bit\"\n",
        "save_steps = 10\n",
        "logging_steps = 10\n",
        "learning_rate = 2e-4\n",
        "max_grad_norm = 0.3\n",
        "max_steps = 30\n",
        "warmup_ratio = 0.03\n",
        "lr_scheduler_type = \"linear\"\n",
        "\n",
        "\n",
        "training_arguments = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    per_device_train_batch_size=per_device_train_batch_size,\n",
        "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "    optim=optim,\n",
        "    save_steps=save_steps,\n",
        "    logging_steps=logging_steps,\n",
        "    learning_rate=learning_rate,\n",
        "    fp16 = not torch.cuda.is_bf16_supported(),\n",
        "    bf16 = torch.cuda.is_bf16_supported(),\n",
        "    max_grad_norm=max_grad_norm,\n",
        "    max_steps=max_steps,\n",
        "    warmup_ratio=warmup_ratio,\n",
        "    group_by_length=True,\n",
        "    lr_scheduler_type=lr_scheduler_type,\n",
        "    gradient_checkpointing=True,\n",
        "    warmup_steps = 5,\n",
        "    weight_decay = 0.01,\n",
        "    seed = 3407\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "ki5GusTa578m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the metrics we need to evaluate the finetuned model on using the test data (precision, recall, F1-score, and accuracy)\n",
        "\n",
        "def custom_metrics(eval_pred):\n",
        "    metric1 = load_metric(\"precision\")\n",
        "    metric2 = load_metric(\"recall\")\n",
        "    metric3 = load_metric(\"f1\")\n",
        "    metric4 = load_metric(\"accuracy\")\n",
        "\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    precision = metric1.compute(predictions=predictions, references=labels, average=\"micro\")[\"precision\"]\n",
        "    recall = metric2.compute(predictions=predictions, references=labels, average=\"micro\")[\"recall\"]\n",
        "    f1 = metric3.compute(predictions=predictions, references=labels, average=\"micro\")[\"f1\"]\n",
        "    accuracy = metric4.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
        "\n",
        "    return {\"precision\": precision, \"recall\": recall, \"f1\": f1, \"accuracy\": accuracy}"
      ],
      "metadata": {
        "id": "QsC2Gj9aVT2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the trainer\n",
        "\n",
        "from trl import SFTTrainer\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    peft_config=peft_config,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_arguments,\n",
        "    compute_metrics=custom_metrics\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q21smsLwupxj",
        "outputId": "c5aeac96-a50c-497c-eca3-1c3747471622"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length. Will not be supported from version '1.0.0'.\n",
            "\n",
            "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:280: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:408: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
            "  warnings.warn(\n",
            "max_steps is given, it will override any value given in num_train_epochs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "outputId": "61565ce3-fd1c-4134-fac2-fe0fc8be1328",
        "id": "7JZtpNxBZT-o"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/CodeExercise-Python-27k/wandb/run-20240803_100804-w6e8nkdl</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/slimmalak97-american-university-of-beirut/huggingface/runs/w6e8nkdl' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/slimmalak97-american-university-of-beirut/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/slimmalak97-american-university-of-beirut/huggingface' target=\"_blank\">https://wandb.ai/slimmalak97-american-university-of-beirut/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/slimmalak97-american-university-of-beirut/huggingface/runs/w6e8nkdl' target=\"_blank\">https://wandb.ai/slimmalak97-american-university-of-beirut/huggingface/runs/w6e8nkdl</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [30/30 57:49, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.590200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.518100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.471800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=30, training_loss=0.5267316977183024, metrics={'train_runtime': 3824.0046, 'train_samples_per_second': 0.063, 'train_steps_per_second': 0.008, 'total_flos': 6589204621565952.0, 'train_loss': 0.5267316977183024, 'epoch': 0.010509261286508736})"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "# Run the training\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDJIomv9r2nX",
        "outputId": "1ad6e185-2ada-45af-96b9-066f7d59040e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'loss': 0.5902,\n",
              "  'grad_norm': 0.20000144839286804,\n",
              "  'learning_rate': 0.00016,\n",
              "  'epoch': 0.003503087095502912,\n",
              "  'step': 10},\n",
              " {'loss': 0.5181,\n",
              "  'grad_norm': 0.13611510396003723,\n",
              "  'learning_rate': 8e-05,\n",
              "  'epoch': 0.007006174191005824,\n",
              "  'step': 20},\n",
              " {'loss': 0.4718,\n",
              "  'grad_norm': 0.13952688872814178,\n",
              "  'learning_rate': 0.0,\n",
              "  'epoch': 0.010509261286508736,\n",
              "  'step': 30},\n",
              " {'train_runtime': 3824.0046,\n",
              "  'train_samples_per_second': 0.063,\n",
              "  'train_steps_per_second': 0.008,\n",
              "  'total_flos': 6589204621565952.0,\n",
              "  'train_loss': 0.5267316977183024,\n",
              "  'epoch': 0.010509261286508736,\n",
              "  'step': 30}]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "trainer.state.log_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSt8H9k0r2nY"
      },
      "outputs": [],
      "source": [
        "# Extract training loss from log_history\n",
        "losses = [log['loss'] for log in trainer.state.log_history if 'loss' in log]\n",
        "steps = [log['step'] for log in trainer.state.log_history if 'loss' in log]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "m9wJVX_Rr2nY",
        "outputId": "fb7581e6-572c-4bdf-c9b8-52585ab1331c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plot the training loss\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting the training loss\n",
        "plt.plot(steps, losses, label='Training Loss')\n",
        "plt.xlabel('Step')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xirbGO2-r2ne",
        "outputId": "b38a9d02-2f0b-4b11-d63e-2f129e1c8a01"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 274.00 MiB. GPU ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-d5017ea0bd3f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Evaluate the fine-tuned model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Print evaluation results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3665\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3666\u001b[0;31m         output = eval_loop(\n\u001b[0m\u001b[1;32m   3667\u001b[0m             \u001b[0meval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3668\u001b[0m             \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Evaluation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3856\u001b[0m             \u001b[0;31m# Prediction step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3857\u001b[0;31m             \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_loss_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3858\u001b[0m             \u001b[0mmain_input_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"main_input_name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3859\u001b[0m             \u001b[0minputs_decode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmain_input_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minclude_inputs_for_metrics\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mprediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[1;32m   4073\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhas_labels\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mloss_without_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4074\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4075\u001b[0;31m                         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4076\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3361\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;31m# To act like a decorator so that it can be popped when doing `extract_model_from_parallel`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_fp32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py\u001b[0m in \u001b[0;36mdecorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautocast_instance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__script_unsupported\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"@autocast() decorator is not supported in script mode\"\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001b[0m\n\u001b[1;32m   1584\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_peft_forward_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1585\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial_peft_forward_args\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1586\u001b[0;31m                 return self.base_model(\n\u001b[0m\u001b[1;32m   1587\u001b[0m                     \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1588\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pre_injection_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPeftConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madapter_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1142\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    942\u001b[0m                 )\n\u001b[1;32m    943\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 944\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m    945\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcausal_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_attention_layernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0mdown_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdown_proj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m             \u001b[0mdown_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgate_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdown_proj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/tuners/lora/bnb.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    500\u001b[0m                         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 274.00 MiB. GPU "
          ]
        }
      ],
      "source": [
        "# Evaluate the fine-tuned model\n",
        "results = trainer.evaluate()\n",
        "\n",
        "# Print evaluation results\n",
        "print(results)\n",
        "\n",
        "# !!!!!!!! NOTE: We were not able to run the evaulation to compute the evaluation metrics due to GPU resources limitation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "\n",
        "import evaluate\n",
        "\n",
        "trainer.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "qTi0eIs5l12q",
        "outputId": "b702d5dc-ab73-41fc-f8da-af4cf9af2ffb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Trainer: evaluation requires an eval_dataset.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-f245b31d31e3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3657\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_memory_tracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3659\u001b[0;31m         \u001b[0meval_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_eval_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3660\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_fsdp_xla_v2_enabled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3661\u001b[0m             \u001b[0meval_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtpu_spmd_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mget_eval_dataloader\u001b[0;34m(self, eval_dataset)\u001b[0m\n\u001b[1;32m    943\u001b[0m         \"\"\"\n\u001b[1;32m    944\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0meval_dataset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_dataset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 945\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trainer: evaluation requires an eval_dataset.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m         \u001b[0;31m# If we have persistent workers, don't do a fork bomb especially as eval datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Trainer: evaluation requires an eval_dataset."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the number of trainable parameters\n",
        "\n",
        "trainable_params = 0\n",
        "all_param = 0\n",
        "for _, param in model.named_parameters():\n",
        "  all_param += param.numel()\n",
        "  if param.requires_grad:\n",
        "    trainable_params += param.numel()\n",
        "print(\n",
        "    f\"trainable params: {trainable_params} || all params: {all_param} || trainables%: {100 * trainable_params / all_param}\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1kQJWwgctzP",
        "outputId": "bb93f5ac-a46e-4c4c-f361-61705f128778"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 167772160 || all params: 4708372480 || trainables%: 3.5632728870252848\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Save the finetuned model and tokenizer"
      ],
      "metadata": {
        "id": "sAZ8zDtoWLxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gj9kTahSike",
        "outputId": "6e79baa5-4ad6-4d33-a95e-2b91ec5e7e4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "\n",
        "# Specify the path to save the model\n",
        "save_directory = \"/content/drive/MyDrive/MSBA 316 NLP/Project/our model\"\n",
        "\n",
        "# Save the tokenizer and the model\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "model.save_pretrained(save_directory)"
      ],
      "metadata": {
        "id": "E88KlXqwSsj1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "aac286d0588947628dd7f7d649e85c40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eba0280d5d364f6f8d1d5cd0997cb267",
              "IPY_MODEL_4c82fa1abaa84ee1865e7ce134f423f0",
              "IPY_MODEL_b01b8cb42da3476ebac672ec74fa6023"
            ],
            "layout": "IPY_MODEL_4c4f22c9f086486bb725b25a5058a958"
          }
        },
        "eba0280d5d364f6f8d1d5cd0997cb267": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6351c61e782945598cdb36ef95e316ee",
            "placeholder": "​",
            "style": "IPY_MODEL_30f6ff0294294f3b860194b54a67d9f1",
            "value": "model.safetensors: 100%"
          }
        },
        "4c82fa1abaa84ee1865e7ce134f423f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0ab6e1f7be54077b2e842ab10b87014",
            "max": 5702746405,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_36d75da0480442c1bc0282472dd3dd53",
            "value": 5702746405
          }
        },
        "b01b8cb42da3476ebac672ec74fa6023": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78d5a6021faf4c4490f37d6b2363ed0d",
            "placeholder": "​",
            "style": "IPY_MODEL_78248972f1c14accb3a0297ea30d1bb3",
            "value": " 5.70G/5.70G [00:50&lt;00:00, 229MB/s]"
          }
        },
        "4c4f22c9f086486bb725b25a5058a958": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6351c61e782945598cdb36ef95e316ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30f6ff0294294f3b860194b54a67d9f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0ab6e1f7be54077b2e842ab10b87014": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36d75da0480442c1bc0282472dd3dd53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "78d5a6021faf4c4490f37d6b2363ed0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78248972f1c14accb3a0297ea30d1bb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2ed31781ec2428bb69f28e3c3529649": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a9da3159492b4b4f90f47abac3c25ece",
              "IPY_MODEL_d15a923b99614b4e87bcfef98b2d070a",
              "IPY_MODEL_ed8590016d7c4c7081be2a9e18229976"
            ],
            "layout": "IPY_MODEL_9a1ea13157a5497483706e6b83baca2a"
          }
        },
        "a9da3159492b4b4f90f47abac3c25ece": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec60c5fa018c46bfb4dedb12f888db17",
            "placeholder": "​",
            "style": "IPY_MODEL_72c3fa0a195d433686fab0e8d4b00004",
            "value": "generation_config.json: 100%"
          }
        },
        "d15a923b99614b4e87bcfef98b2d070a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad51e64d5b864691b168f1fc31861f04",
            "max": 172,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_03134366a494446fbef4bd7bae88b7db",
            "value": 172
          }
        },
        "ed8590016d7c4c7081be2a9e18229976": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12340872cad5492799e89366d689dbd5",
            "placeholder": "​",
            "style": "IPY_MODEL_c90692b688cd4fc38c83d797163583f3",
            "value": " 172/172 [00:00&lt;00:00, 10.5kB/s]"
          }
        },
        "9a1ea13157a5497483706e6b83baca2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec60c5fa018c46bfb4dedb12f888db17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72c3fa0a195d433686fab0e8d4b00004": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad51e64d5b864691b168f1fc31861f04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03134366a494446fbef4bd7bae88b7db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "12340872cad5492799e89366d689dbd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c90692b688cd4fc38c83d797163583f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}